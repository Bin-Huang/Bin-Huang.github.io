[{"categories":null,"contents":"一个命令行工具，用来自动生成 Go 结构体的构造器代码\n","date":"Aug 11","permalink":"/projects/make-constructor/","tags":null,"title":"Newc"},{"categories":null,"contents":"不算作品，只是开发了两个晚上的“玩具项目”，但出乎意外的有趣～\n","date":"Nov 03","permalink":"/projects/jk-broadcast/","tags":null,"title":"即刻镇广播(DEMO)"},{"categories":null,"contents":"一个 JavaScript/TypeScript 工具库，提供 “Promisified Array” 的基础工具\n","date":"Nov 03","permalink":"/projects/prray/","tags":null,"title":"Prray"},{"categories":null,"contents":"一个在线服务，用来给 Kindle 订阅 RSS，可以定时收到像报纸杂志一样的文章合集。它曾是我大学时期的⭐骄傲⭐\n","date":"Feb 15","permalink":"/projects/wml/","tags":null,"title":"WhereMyLife"},{"categories":null,"contents":"这里记录了 WhereMyLife 的前世今生和更新记录\n","date":"Feb 15","permalink":"/projects/wml-blog/","tags":null,"title":"WhereMyLife Blog"},{"categories":null,"contents":"一个 Node.js 爬虫框架，当时我花了太多时间在这上面……\n","date":"Jan 01","permalink":"/projects/nodespider/","tags":null,"title":"NodeSpider"},{"categories":null,"contents":"远古早期作品，在大学寝室开发的高级计算器App，特点是支持矩阵计算\n","date":"Jan 01","permalink":"/projects/zhizi/","tags":null,"title":"智子计算器"},{"categories":null,"contents":"   导语  “成熟的工具，要学会自己写代码”。本文介绍了 Go 依赖注入工具 [[Wire]] 及其使用方法，以及在实践中积累的各种运用技巧。当代码达到一定规模后，[[Wire]] 在组件解耦、开发效率、可维护性上都能发挥很大的作用，尤其在大仓场景。\n   依赖注入  当项目变得越来越大，代码中的组件也越来越多：各种数据库、中间件的客户端连接，分层设计中的各种库表 repositories 实例、services 实例……\n这时为了代码的可维护性，应该避免组件之间的耦合。具体的做法可以遵守一个重要的设计准则：所有依赖应该在组件初始化时传递给它，这就是依赖注入（Dependency injection）。\n Dependency injection is a standard technique for producing flexible and loosely coupled code, by explicitly providing components with all of the dependencies they need to work.\n\u0026ndash; Go 官方博客\n 下面是个简单的例子，所有组件 Message、Greeter、Event 自身的依赖都在初始化的时候获得。\n1 2 3 4 5 6 7  func main() { message := NewMessage() greeter := NewGreeter(message) event := NewEvent(greeter) event.Start() }      Wire 介绍  当项目中实例依赖（组件）的数量越来越多，如果还是人工手动编写初始化代码和维护组件之间依赖关系的话，会是一件非常繁琐的事情，而且在大仓中尤其明显。因此，社区里已经有了不少的依赖注入框架。\n除了来自 Google 的 Wire 以外，还有 Dig（Uber） 、Inject（Facebook）。其中 Dig 和 Inject 都是基于 Golang 的 Reflection 来实现的。这不仅对性能产生影响，而且依赖注入的机制对使用者不透明，非常的“黑盒”。\n Clear is better than clever ，Reflection is never clear.\n— Rob Pike\n 相比之下，Wire 完全基于代码生成。在开发阶段，wire 会自动生成组件的初始化代码，生成代码人类可读，可以提交仓库，也可以正常编译。因此 Wire 的依赖注入非常透明，也不会带来运行阶段的任何性能损耗。\n   上手介绍  这里快速介绍一下 Wire 的使用方法\n   第一步：下载安装 Wire  下载安装 wire 命令行工具\n1  go install github.com/google/wire/cmd/wire@latest      第二步：创建 wire.go 文件  在生成代码之前，我们先声明各个组件的依赖关系和初始化顺序。在应用入口创建一个 wire.go 文件。\ncmd/web/wire.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // +build wireinject  package main import \u0026#34;...\u0026#34; // 简化示例  var ProviderSet = wire.NewSet( configs.Get, databases.New, repositories.NewUser, services.NewUser, NewApp, ) func CreateApp() (*App, error) { wire.Build(ProviderSet) return nil, nil }   这个文件不会参与编译，只是为了告诉 Wire 各个组件的依赖关系，以及期望的生成结果。在这个文件：我们期望 Wire 生成一个返回 App 实例或 error 的 CreateApp 函数，App 实例初始化所需要的全部依赖都由 ProviderSet 这个组件列表提供，而 ProviderSet 声明了所有可能需要的组件的获取/初始化方法，也暗示组件之间的依赖顺序。\n 组件的获取/初始化方法，在 Wire 中叫做“组件的 provider”\n 还有几点需要注意：\n 文件开头必须带上 // +build wireinject 和随后的空行，否则会影响编译 在这个文件中，编辑器和 IDE 可能无法提供代码提示，但没关系，稍后会介绍如何解决这个问题 其中 CreateApp 的返回（两个 nil）没有任何意义，只是为了兼容 Go 语法。     第三步：生成初始化代码  命令行执行 wire ./...，然后就能得到下面这个自动生成的代码文件。\ncmd/web/wire_gen.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  // Code generated by Wire. DO NOT EDIT.  //go:generate go run github.com/google/wire/cmd/wire //go:build !wireinject // +build !wireinject  package main import \u0026#34;...\u0026#34; // 简化示例  func CreateApp() (*App, error) { conf, err := configs.Get() if err != nil { return nil, err } db, err := databases.New(conf) if err != nil { return nil, err } userRepo, err := repositories.NewUser(db) if err != nil { return nil, err } userSvc, err := services.NewUser(userRepo) if err != nil { return nil, err } app, err := NewApp(userSvc) if err != nil { return nil, err } return app, nil }      第四步：使用初始化代码  Wire 已经帮我们生成了真正的 CreateApp 初始化方法，现在可以直接使用它。\ncmd/web/main.go\n1 2 3 4 5  // main.go func main() { app := CreateApp() app.Run() }      使用技巧     组件按需加载  Wire 有个优雅的特点，不管在 wire.Build 中传入了多少个组件的 provider，Wire 始终只会按照实际需要来初始化组件，所有不需要的组件都不会生成相应的初始化代码。\n因此，我们在使用时可以尽可能地提供更多的 provider，把挑选组件的工作交给 Wire。这样我们在开发时不管引用新组件、还是弃用老组件，都不需要修改初始化步骤的代码 wire.go。\n比如，可以把 services 层中所有的实例构造器都提供出去。\npkg/services/wire.go\n1 2 3 4  package services // 提供了所有 service 的实例构造器 var ProviderSet = wire.NewSet(NewUserService, NewFeedService, NewSearchService, NewBannerService)   在初始化中，尽可能地引用所有可能需要的组件 provider。\ncmd/web/wire.go\n1 2 3 4 5 6 7 8 9 10 11 12  var ProviderSet = wire.NewSet( configs.ProviderSet, databases.ProviderSet, repositories.ProviderSet, services.ProviderSet, // 引用了所有 service 的实例构造器 \tNewApp, ) func CreateApp() (*App, error) { wire.Build(ProviderSet) // wire 会按照实际需要，选择性地进行初始化 \treturn nil, nil }   在后续开发中，如果需要引用新组件，只需要加到参数里即可。Wire 会任劳任怨地按照实际需要，生成需要的组件的初始化代码。\n1 2  func NewApp(user *UserService, banner *BannerService) { }   即使 Wire 找不到组件的 provider，也会提前在编译阶段报错，不会在线上运行阶段出现问题。\nwire: cmd/api/wire.go:23:1: inject CreateApp: no provider found for *io.WriteCloser    编辑器与 IDE 的辅助配置  因为 wire.go 文件中加了这行注释，Go 在编译时会跳过这个文件，但也因此会影响编辑器和 IDE 的代码提示。当你在编辑 wire.go 文件时，常见的编辑器和 IDE 都无法正常地提供代码补全和错误提示功能。\n1  // +build wireinject   但这个问题很容易解决。找到 IDE/编辑器的 Go 环境配置，在 Go Build Flags 中添加这个参数 -tags=wireinject 就可以了。\n这个配置可以让编辑器和 IDE 正常地为 wire.go 文件提供代码补全和错误提示功能，开发体验提高不只一个数量级～\n   多个同类型组件的冲突问题  这个问题比较少见，但项目大了总是容易遇到。\nWire 通过 provider 的参数与返回类型，来判断组件的依赖关系。有时候，依赖网络中可能出现同类型的不同组件，这时 Wire 无法正确判断依赖关系，会直接报错。\nprovider has multiple parameters of type ... 比如下面这个 provider，依赖的 MySQL 和 PostgreSQL 客户端实例的类型是完全相同的（都是 *gorm.DB），这时 Wire 无法根据类型正确地判断依赖关系，生成代码时会直接报错。\n1 2 3  // 这个 service 同时使用了 mysql 和 pg 中的数据，但是两个组件的类型是相同的 func NewService(mysql *gorm.DB, pg *gorm.DB) *Service { }   解决的方法也比较简单，只需要做一层类型的包装。\n1 2 3 4 5 6 7 8 9 10  type Mysql gorm.DB type Pg gorm.DB // 在参数中用类型别名进行区分 func ProviderSerivce(mysql *Mysql, pg *Pg) *Service { // 函数内再转回原来的类型 \tr1 := (*gorm.DB)(mysql) r2 := (*gorm.DB)(pg) return NewService(r1, r2) }   然后用 ProviderSerivce 代替 NewService 即可。\n1 2 3 4 5  wire.Build( ProviderMysql, // func() *Mysql \tProviderPg, // func() *Pg \tProviderSerivce, // func(mysql *Mysql, pg *Pg) *Service )      自动生成构造函数  当项目中充当抽象类的结构体越来越多，手动编写和维护结构体的构造函数，也是一件非常繁琐的事情。如果结构体中新增了一个指针类型的成员、却忘记更新构造函数，甚至还会引起线上 panic。\n1 2 3 4 5 6 7 8 9 10 11  type Service struct { repo *Repository logger *zap.Logger // 添加这个成员后，忘记更新构造函数了 } func NewService(repo *Repository) *Service { // 缺失 logger，可能在线上出现空指针错误 \treturn \u0026amp;Service { repo: repo, } }   像这种繁琐、重复、容易出错的工作，就应该交给自动工具来完成。这里我毛遂自荐一个自动工具 newc（意为 “New Construtor”），它可以自动生成与更新结构体的构造函数代码。\n使用方法非常简单，只需要给结构体添加这行注释。\n//go:generate go run github.com/Bin-Huang/newc@v0.8.3 比如这样：\n1 2 3 4 5 6 7  // My User Service //go:generate go run github.com/Bin-Huang/newc@v0.8.3 type UserService struct { baseService userRepository *repositories.UserRepository proRepository *repositories.ProRepository }   然后命令行执行 go generate ./... 即可获得构造函数代码：\nconstructor_gen.go\n1 2 3 4 5 6 7 8  // NewUserService Create a new UserService func NewUserService(baseService baseService, userRepository *repositories.UserRepository, proRepository *repositories.ProRepository) *UserService { return \u0026amp;UserService{ baseService: baseService, userRepository: userRepository, proRepository: proRepository, } }   这个工具和 Wire 搭配使用，开发体验非常好。要使用新组件时，直接在结构体中添加成员就好了，不需要手动更新构造函数，也不需要考虑初始化的问题，所有重复的工作都交给自动工具（Wire 和 Newc）来完成。线下推荐过的同学，用过都说好。\n当然这个工具也一定有考虑不周的情况，很期待大家的反馈和建议。\n Don\u0026rsquo;t repeat yourself \u0026ldquo;DRY\u0026rdquo;\n    总结  Wire 可以完美地解决依赖注入的问题，但它不是一个框架，它没有”魔法“，也不是黑盒。它只是一个命令行工具，它根据实际需要，自动生成了各个组件的初始化代码。然后问题就解决了，没有额外的复杂性，没有运行的性能损耗。\nWire 和 [[Golang]] 的气质如出一辙，简单、直接、实用主义，不愧是 Go 最优雅的依赖注入工具！\n Keep it simple stupid \u0026ldquo;K.I.S.S\u0026rdquo;\n ","date":"Aug 24","permalink":"/posts/wire/","tags":null,"title":"Wire：Go最优雅的依赖注入工具"},{"categories":null,"contents":"我追逐一个线上问题的幽灵，直到淹没在迷惑的日志森林里。我在脑海中苦苦思索，身后一声惊奇的鸦叫，我猛然发现当作指南针的 Sentry 报告，才是真正的迷惑来源……\n   发现问题  我们项目中使用 Sentry 来捕获错误，顺便会附带一些上下文，比如用户 ID、请求链路、版本环境……这些上下文在排查时非常有用，然而最近却误导了我，让我在错误的方向上花了不少时间，回过头来才发现上下文是有误的。\n具体来说，原本是用户 A 触发了某个错误，Sentry 上报错误的上下文里却显示是用户 B 触发的。我进一步发现，这种 Sentry 误报并不是稳定出现，而是随机出现在项目几乎所有种类的错误报告里。出于直觉，我认为这很可能是一个并发冲突问题：比如 Sentry 在报告上下文时出现了并发冲突。\n   实验模拟  下面是一段最简单的实验代码：我们启动了两个并发的协程、分别不断地上报自己的错误，然后观察两个协程的错误上下文会不会互相干扰。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // 协程一：不断上报错误 test-sentry-1，并附带上下文 {Username: \u0026#34;1\u0026#34;} go func() { for { sentry.WithScope(func(scope *sentry.Scope) { scope.SetUser(sentry.User{Username: \u0026#34;1\u0026#34;}) sentry.CaptureException(errors.New(\u0026#34;test-sentry-1\u0026#34;)) }) } }() // 协程二：不断上报错误 test-sentry-2，并附带上下文 {Username: \u0026#34;2\u0026#34;} go func() { for { sentry.WithScope(func(scope *sentry.Scope) { scope.SetUser(sentry.User{Username: \u0026#34;2\u0026#34;}) sentry.CaptureException(errors.New(\u0026#34;test-sentry-2\u0026#34;)) }) } }()   很快我们就会发现，在 Sentry 上报的错误中，已经随机出现了错误上下文混乱的情况。比如在下图，在代码中上报错误 test-sentry-2 附带了 {Username: \u0026quot;2\u0026quot;} 的上下文信息，但 Sentry 实际却上报了 {Username: \u0026quot;1\u0026quot;} 的上下文。很明显这个错误的上下文被其他并发协程影响了。\n抓个正着！看来 Sentry 报告上下文时确实出现了并发冲突（至少目前看来如此……）。\n   理论原因  查看 sentry-go 的源码，发现实现代码里常常出现这两个结构体 Scope 和 Hub。\n Scope：即上下文，存放为错误追加的额外信息，比如用户 ID、请求 ID、请求路径、附加标签…… Hub：也许可以叫“捕获器”，内部维护了一个上下文堆栈。  Hub.stack：一个堆栈，由多层 layer 组成 Hub.stack[0].client：每一层包含服务连接实例 Hub.stack[0].scope：每一层也可能包含当前上下文    当我们上报错误时，每次执行 sentry.CaptureException(err)，实际上是从当前 hub 中获取最新的上下文（一般位于 stack 顶层，若当前层没有则查找下一层），然后与错误一起通过服务连接上报。\n而添加/删除上下文时，可以用 hub.PushScope() 或 hub.PopScope() 方法，即为 hub 的内部堆栈压入一个包含上下文信息的新堆栈层，或者弹出不再需要的层。我们一般用 WithScope 方法来附加一些临时的上下文。这个方法的原理是执行传入函数，在传入函数执行前自动 push，在执行后自动 pop。\n1 2 3 4 5  // WithScope 方法的使用案例 sentry.WithScope(func(scope *sentry.Scope) { scope.SetUser(sentry.User{Username: \u0026#34;1\u0026#34;}) sentry.CaptureException(errors.New(\u0026#34;test-sentry-1\u0026#34;)) })   其中 WithScope 的源码实现：\n1 2 3 4 5 6  // Sentry 的 WithScope 方法源码 func (hub *Hub) WithScope(f func(scope *Scope)) { scope := hub.PushScope() defer hub.PopScope() f(scope) }   通过阅读源码，很明显 WithScope 这个方法在并发下不安全。如果一个协程用 WithScope 刚刚压入新层、正在编辑上下文，然后另一个协程也压入了新层，那么就会出现并发冲突，比如污染其他协程的上下文、或者用其他协程的上下文来上报自己的错误！\n   设计如此？  难道要怪 Sentry 客户端库存在漏洞？不，设计如此，或者更像是迫不得已。\nSentry 基于 Scope Stack 的设计可以很方便地继承和拓展上下文，尤其在程序不同层级之间很有用。因为 Sentry 不是只面向 Golang 这门语言，还需要支持 Node.js、Python、PHP、C#……所以 Sentry 必须要在所有语言中尽可能做到接口统一，像 push、pop、withScope 这类操作都是统一提供的。然而在 Golang 中，要让 WithScope 方法做到全局并发安全几乎不太现实。因为如果加锁的话，WithScope 的错误上报只能串行执行了，严重影响了上报性能。\n   规避方法  既然全局并发安全做不到，那么局部并发安全还是可以有的。只要每个协程都有一个自己专属的上下文堆栈，那么就不用担心互相污染的问题。为此 Sentry 专门提供了 hub.Clone() 方法。\n1 2 3 4 5 6 7  go func () { hub := sentry.CurrentHub().Clone() // 获得新 hub \thub.WithScope(func(scope *sentry.Scope) { // 为新 hub 添加上下文 \tscope.SetTag(\u0026#34;action\u0026#34;, \u0026#34;produce\u0026#34;) hub.CaptureException(err) // 用新 hub 上报错误 \t}) }()   Clone() 方法会引用当前 hub 的底层服务连接，并复制一份当前的上下文堆栈的拷贝，然后生成一个新的 hub 实例。因为复用了底层服务连接，很明显 hub 克隆的成本很低，可以随用随抛。因此在实践中，不管是否存在并发，上报错误时都最好克隆一下 hub 实例。\n这个方法可以完美地规避并发冲突问题，nice~\n","date":"Mar 21","permalink":"/posts/sentry-hub-scope/","tags":null,"title":"Sentry 高并发时上报异常的问题排查"},{"categories":null,"contents":"   前言  众所周知，ElasticSearch 中的 Mapping 决定了字段的索引方式。当一个字段的索引类型确定后就无法修改。然而在日常开发中，忘记更新 mapping 是偶尔会遇到的，但修改 mapping 却是一件不容易的事情。这篇文章不仅详细讨论了 reindex 这种常见解决方法，包括 reindex 的停机和数据丢失问题、以及在各种情况下规避上述问题的思路和方法，还介绍了另外两种更加低成本的解决方法。\n   一个常见的错误  “发布测试环境前我竟然忘记修改 mapping 了？”\n{\u0026quot;error\u0026quot;:{\u0026quot;root_cause\u0026quot;:[{\u0026quot;type\u0026quot;:\u0026quot;illegal_argument_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;Fielddata is disabled on text fields by default. Set fielddata=true on [player_type] in order to load fielddata in memory by uninverting the inverted index...... 所以我要如何快速解决这个问题呢？ 所以我要如何快速修改 mapping 中一个字段的索引类型呢？\n   Reindex  “即使对 reindex 烂熟于心，也需要留意停机时间和数据丢失……”\nReindex 几乎是这类问题的标准答案，其中一个常见思路是：创建一个新的 index-tmp，然后把数据 reindex 到这个新 index-tmp，再把原来的 index 删除重建、设置正确的 mapping，最后把数据重新从 index-tmp 中 reindex 回来。很明显这个思路除了操作危险外，还会有较长的停机时间。\nElasticSearch 官方博客里曾介绍过另一种方法，只要后端业务以 alias 的方式访问 index，就可以做到完全无停机时间（Zero-Downtime）。具体思路是：首先创建一个 mapping 正确的新 index-v2，把数据 reindex 到这个新 index-v2，然后直接把 alias 重命名到这个index-v2。这样可以让后端业务直接访问到新的 index-v2，达到后端业务对 reindex 操作无感知的效果。\n然而这种方法也有不足，官方博客里完全没有提及数据丢失的问题。如果线上写入操作频繁，在 reindex 和更新 alias 步骤中有一段时间窗口，新数据依然会写入到即将弃用的旧 index，造成新 index-v2 丢失该部分数据的问题。即使采用官博推荐的 bulk API，也无法在原理上根本地规避问题。\n因此需要结合实际的业务情况，做一些因地制宜的权衡。\n1. 那就丢亿点点数据\n有时候，丢失一些临时数据也是可以接受的，比如测试环境的PV上报、用来时间窗口统计的热词记录……对于这些可丢失数据，当我们发出那句灵魂拷问，“数据重要还是我重要下班重要！”，相信产品经理也是会认真考虑的。\n2. 找个夜黑风高的时候停机\n防止新数据丢失最简单的办法就是停机了。只要没有写入，哪来数据丢失。在我常常遇到的 ES 使用场景里，新数据总是通过消费者从其他数据源里同步过来，只要先让消费者暂停就可以解决问题。后端业务还是可以正常读取 ES，只是停止了消费者的写入。当一切结束后，消费者可以直接从消息队列里获取堆积的写入任务，轻松地恢复工作。\n3. 让新数据先走\n能不能在不停机的情况下，也能做到不丢失数据？完全可以。创建新 index 后，立即重新设置 alias，让新 index 先开始接受新数据，然后再把老数据 reindex 过来。这样数据要么在新 index、要么在旧 index，但最终都会写入在新 index，解决了新文档丢失的问题。\n但我也想到了这种方法的几个不足和局限：\n 中间会有很长一段时间（当新 index 开始接客、旧数据还没有全部 reindex 过来时），后端业务将无法访问到旧数据。这可能会对业务造成影响，比如用户突然无法搜索到以前的文章。 这个方法只能保证新文档插入不丢失，对旧文档的更新和删除操作依然可能丢失。当然，如果业务里 ES 的使用场景是“只写不改”，那也就不是问题了。不过说起来，把 ES 用来作为 CRUD 数据库确实是很奇怪的技术选型～  4. 两步 reindex\n我还想到了一个方法，可以在不停机的情况下，既让后端业务尽可能正常地访问老数据，又不丢失新文档的创建。这个方法要求文档创建时附带一个 created_at 字段。\n 创建一个新的 index-v2，设置好需要的 mapping。  PUT /index-v2/_doc/_mapping { \u0026quot;properties\u0026quot;: \u0026lt;all_you_need\u0026gt; } 先“悄悄”准备老数据，比如先 reindex 某个时间点之前的老数据（比如一小时前）。  POST _reindex { \u0026quot;source\u0026quot;: { \u0026quot;index\u0026quot;: \u0026quot;index-v1\u0026quot;, \u0026quot;query\u0026quot;: { \u0026quot;range\u0026quot;: { \u0026quot;created_at\u0026quot;: { \u0026quot;lt\u0026quot;: \u0026lt;一个时间点\u0026gt; } } } }, \u0026quot;dest\u0026quot;: { \u0026quot;index\u0026quot;: \u0026quot;index-v2\u0026quot; } } 当老数据准备好后，立即修改 alias，让新 index-v2 开始接受新数据。  POST /_aliases { \u0026quot;actions\u0026quot;: [ { \u0026quot;remove\u0026quot;: { \u0026quot;alias\u0026quot;: \u0026quot;index\u0026quot;, \u0026quot;index\u0026quot;: \u0026quot;index-v1\u0026quot; } }, { \u0026quot;add\u0026quot;: { \u0026quot;alias\u0026quot;: \u0026quot;index\u0026quot;, \u0026quot;index\u0026quot;: \u0026quot;index-v2\u0026quot; } } ] } 再将这个时间点之后的数据 reindex 到新 index-v2  POST _reindex { \u0026quot;source\u0026quot;: { \u0026quot;index\u0026quot;: \u0026quot;index-v1\u0026quot;, \u0026quot;query\u0026quot;: { \u0026quot;range\u0026quot;: { \u0026quot;created_at\u0026quot;: { \u0026quot;gte\u0026quot;: \u0026lt;一个时间点\u0026gt; } } } }, \u0026quot;dest\u0026quot;: { \u0026quot;index\u0026quot;: \u0026quot;index-v2\u0026quot; } } 这样在迁移过程中，既不需要停机，也不会丢失新数据，也不会出现长时间无法访问历史数据的问题。后端业务几乎可以访问到所有的数据，只有在第二次 reindex 期间会有极小部分数据在短时间内无法访问（不可见数据范围大约是 created_at: [the_timestamp, now）），但也会很快地恢复。因为数据量非常少，第二次 reindex 速度很快，等到结束后，后端业务就可以完全正常地访问到所有的数据。\n这个方法可以保证新文档插入不丢失、大部分旧文档更新删除不丢失，但在第二次 reindex 期间那些不可见文档的更新、删除操作依然有丢失的可能。这个方法在不停机的前提下大幅地缩小了负面影响的范围。\n小结\n以上只是尽可能地讨论了 reindex 在实际业务中可能遇到的问题，以及可行的方法与思路。虽然在实际应用中，大多数情况都可以用简单直接的方法解决，比如遗弃数据和停机，但认识更多情况可以规避潜在的决策风险。\n对了，这里没有讨论 reindex 优化，我感觉这是另外一个话题了。我看到有些高赞文章提到通过配置来增大 reindex 单次索引的文档数量，或者通过 scroll 并发来加快索引。我直观的感觉，这些方法在停机情况下应该是不错的做法，但在不停机时可能会给集群带来更多的压力，尤其是 index 数据量很大、读写频繁的场景，可能会影响到正常的业务。在不停机的情况，也许我们应该更多考虑的不是如何加快 reindex 过程，而是尽可能降低 reindex 对正常业务的影响。\n除了 reindex，还有其他一些方法可以“修改”已有字段的索引类型。\n   新字段替换  “既然不能直接修改原来字段的索引类型，那我重新建个字段好吧……”\n很多时候，为了一点点错误索引的数据而 reindex 整个 index，也许是一件大动干戈的事情。利用其他技巧可以更加低成本的解决问题，比如建个新字段。\n 在 mapping 添加新字段 new_field，设置好需要的索引方式  PUT /my-index/_doc/_mapping { \u0026quot;properties\u0026quot;: { \u0026quot;new_field\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; } } } 将原来文档的旧字段的值重新赋予到新字段  POST /my-index/_update_by_query?conflicts=proceed { \u0026quot;script\u0026quot;: { \u0026quot;source\u0026quot;: \u0026quot;ctx._source.new_field = ctx._source.old_field\u0026quot;, \u0026quot;lang\u0026quot;: \u0026quot;painless\u0026quot; }, \u0026quot;query\u0026quot;: { \u0026quot;exists\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;old_field\u0026quot; } } } 在业务代码中弃用原来的字段  小结\n这个方法非常适合低成本解决少量数据被错误索引的情况，比如在发布前忘记修改 mapping。但是如果需要修改索引类型的数据很多，这个方法需要更新大量已有数据，可能会对集群带来一定压力。毕竟在 ElasticSearch 里，所谓的文档修改就是先标记删除、然后重新插入，如果要更新整个 index 的所有文档，也许还不如 reindex 来得痛快……\n   采用 multi-field  \u0026ldquo;作为一个成熟的 DB，总是可以为一个字段建立多种索引……\u0026quot;\nElasticSearch 的 multi-field 特性，让同一个字段可以有多种不同的索引类型。我们可以利用这个特性在 mapping 中为老字段追加新的索引类型。比如这个例子：\nPUT /my-index/_doc/_mapping { \u0026quot;properties\u0026quot;: { \u0026quot;company\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;, \u0026quot;fields\u0026quot;: { \u0026quot;name\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } } } } 原本 company 字段采用了 keyword 的索引类型，只能用于数值匹配。在上面的例子中，为 company 字段追加了另一种支持全文搜索的索引类型 text，然后把这个全文搜索版本取名叫 company.name。这样查询条件 { \u0026quot;company.name\u0026quot;: \u0026quot;腾讯\u0026quot; } 就可以匹配到 { \u0026quot;company\u0026quot;: \u0026quot;腾讯科技有限公司\u0026quot; } 的数据了。\n因为本质上只是对同一个字段添加不同的索引，实际文档（documents）中并不会真的多出来一个叫 company.name 的字段，插入数据时也不需要为 company.name 赋值。一切索引工作都由 ElasticSearch 自动完成。\n然而用这种方法修改 mapping 后，只有新的写入才会让该文档的新索引生效。也就是说，只有插入新的文档、或者更新旧文档时，ElasticSearch 才会给该文档重新索引、将该文档写入新索引。除非老数据有更新，用 company.name 无法搜索到老数据，因为老数据根本不在这个索引里！\n但问题总是可以解决，不就是还差一次全局更新嘛～（坏笑脸\n// 这个更新没有任何意义，纯粹是为了触发老数据的重新索引 POST /my-index/_update_by_query?conflicts=proceed { \u0026quot;script\u0026quot;: { \u0026quot;source\u0026quot;: \u0026quot;ctx\u0026quot;, \u0026quot;lang\u0026quot;: \u0026quot;painless\u0026quot; }, \u0026quot;query\u0026quot;: { \u0026quot;exists\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;company\u0026quot; } } } 小结\n这个方法不仅适合低成本解决少量数据被错误索引的情况，而且在同个字段需要多种索引方式（尤其需要是搭配不同的分析器）时这几乎是唯一的做法，因为 multi-field 就是为了这种场景准备的。但这个方法同样需要注意更新数据的规模，以及对性能的影响……\n   最后  我在中英互联网上搜索时，发现很难找到详细讨论这个话题的文章。其中我找到最好的资料是 ElasticSearch 官博的一篇文章，里面简要介绍了这三种方法，但是很少介绍各个方法的局限、已知问题和适用场景，比如几乎没有提到 reindex 的数据丢失问题。我还找到了很多只言片语，它们大多只是简单提供了一个解决方法，却很少介绍方法的用意和局限。\n所以我尝试写篇文章，想着结合自己的认识和理解，试着更加全面地讨论一下各个方法的利弊权衡，看看能不能从这个常见的小问题出发，窥探到一点点原理和设计的影子，填补一点点底层技术与实际业务的缝隙，引发一些可能的讨论和思路。\n最后不得不感叹：方法常有，银弹难寻！只有根据实际情况，在业务可接受的影响范围内，找到最简单方法，往往那就是最佳实践。\n   参考   https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html https://www.elastic.co/guide/en/elasticsearch/reference/current/multi-fields.html https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-put-mapping.html#add-multi-fields-existing-field-ex  ","date":"Feb 14","permalink":"/posts/es-mapping/","tags":null,"title":"深入讨论几种 ES Mapping 修改方法和局限"},{"categories":null,"contents":"","date":"Jan 01","permalink":"/projects/","tags":null,"title":"作品"},{"categories":null,"contents":"","date":"Jan 01","permalink":"/articles/","tags":null,"title":"文章"}]